# .github/workflows/check_archive.yml
name: Notify Upon Failure

on:
  workflow_run:
    #workflows: ["Link Checker"]
    workflows: ["NONE"]
    types:
      - completed

  workflow_dispatch:

jobs:
  check-archive:
    name: Check Archive File
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python for link checking
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          pip install requests
          pip install PyGithub

      - name: Configure Git
        run: |
          git config user.name "${{ secrets.ACTIONS_USERNAME }}"
          git config user.email "${{ secrets.ACTIONS_EMAIL }}"

      - name: Create and run the link check script
        run: |
          echo '
          import re
          import requests
          from github import Github

          GITHUB_TOKEN = "${{ secrets.ACTIONS_TOKEN }}"
          REPO_NAME = "${{ github.repository }}"

          # Initialize GitHub client
          g = Github(GITHUB_TOKEN)
          repo = g.get_repo(REPO_NAME)

          # Read the Archive.md file
          with open("Archives.md", "r") as archive_file:
              archive_content = archive_file.read()

          # Regex to find all links in Archives.md
          link_pattern = re.compile(r"\[.*?\]\((https:\/\/.*?)\)")
          links = link_pattern.findall(archive_content)
          print(f"Found links: {links}")

          # Track links that fail and pass
          failed_links = []
          working_links = []

          for url in links:
              try:
                  response = requests.head(url)
                  if response.status_code == 404:
                      print(f"Failed link detected: {url}")
                      failed_links.append(url)
                  else:
                      print(f"Working link: {url}")
                      working_links.append(url)
              except Exception as e:
                  print(f"Exception occurred: {e} on URL: {url}")
                  failed_links.append(url)

          print(f"Failed links: {failed_links}")
          print(f"Working links: {working_links}")

          # Close issues for working links and open issues for failing links
          issues = repo.get_issues(state="open", labels=["❌ Bad Link"])
          print(f"Existing issues: {[issue.title for issue in issues]}")

          # Close issues for working links
          for issue in issues:
              if any(link in issue.body for link in working_links):
                  print(f"Closing issue: {issue.title}")
                  issue.edit(state="closed")

          # Open issues for failing links
          for failed_link in failed_links:
              file_name = failed_link.split("/")[-1]
              title = f"404: {file_name}"
              body = (
                  f"❌ **404 Link Failure**\n\n"
                  f"**File Name:** {file_name}\n"
                  f"**URL:** {failed_link}\n\n"
                  f"Link is referenced in the `Archives.md` file."
              )

              # Check if issue already exists
              existing_issues = repo.get_issues(state="open", labels=["❌ Bad Link"])
              issue_exists = any(failed_link in issue.body for issue in existing_issues)

              if not issue_exists:
                  print(f"Creating issue: {title}")
                  repo.create_issue(
                      title=title,
                      body=body,
                      labels=["❌ Bad Link"]
                  )
              else:
                  print(f"Issue already exists for: {failed_link}")
          ' > check_links.py
          python3 check_links.py

      - name: Report Results
        run: |
          echo "Report Links Checked and Issues Managed."
